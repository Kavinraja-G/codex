{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udc4b Hola amigo!","text":"<p>I\u2019m a Cloud Enthusiast and DevOps Advocate passionate about building resilient cloud ecosystems and crafting custom Kubernetes solutions. I thrive on solving complex cloud-native challenges and transforming them into secure, cost-efficient, and scalable systems. My journey is driven by continuous learning, mentoring, and an unwavering pursuit of innovation \ud83d\ude80</p> <p>Currently working as a Senior Site Reliability Engineer at a Confidential Identity Company. Formerly with Presidio</p>"},{"location":"blog/","title":"Blogs","text":""},{"location":"blog/#blogs","title":"Blogs","text":"<p>Everything I learn &amp; tinker with </p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/","title":"Monitoring RPi using Grafana Cloud & Alloy","text":""},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#monitoring-rpi-using-grafana-cloud-alloy","title":"Monitoring RPi using Grafana Cloud &amp; Alloy","text":""},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#problem","title":"Problem","text":"<p>I have an old Raspberry PI 3 that I used during my college days for applications like drones and robotics. Recently, I decided to repurpose it to run a simple Pi-hole setup to block ads across my home network and devices. One day, my RPi unexpectedly froze, and I had no idea that my DNS requests were failing until I noticed connectivity issues. A reboot resolved the problem, but it made me realize the need for proactive monitoring. Since my router is configured to use Pi-hole as both the primary and secondary DNS (yes, I know I should have a better failover strategy but for now, it works fine), a failure like this can disrupt my entire network.</p> <p>This got me thinking \u2014 why not monitor my Raspberry Pi to catch these issues before they cause problems? Given that it's still a critical piece of hardware in my setup, I need a reliable and highly available monitoring solution. However, I don\u2019t want to self-host my monitoring services; I prefer a managed, cloud-hosted solution that I can trust. Well, I might change this thought in future. More on that later :)</p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#why-grafana-cloud-alloy","title":"Why Grafana Cloud &amp; Alloy?","text":"<p>Grafana Cloud: I had very good experience with Grafana, Prometheus and its stack in my work, so I thought why not give a try with their Grafana Cloud variant. And then came to know it offers really good free-tier experience which fits for my use-case.</p> <p>What comes with Cloud free?</p> <p>Metrics 10k metrics billable series; Logs, Traces, Profiles 50 GB each all with 14 days retention</p> <p>This is more than enough to monitor my devices.</p> <p>Grafana Alloy: It is a flexible, high-performance, vendor-neutral distribution of the OpenTelemetry Collector which is an alternative for the Grafana agent. It\u2019s fully compatible with popular open-source observability standards like OpenTelemetry and Prometheus. This was my first time using Alloy and I must say, the setup was straightforward and hassle-free.</p> <p>In my setup, Alloy runs as an agent on my Raspberry Pi, collecting and forwarding metrics to Grafana Cloud.</p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#setup-raspberry-pi-integration","title":"Setup Raspberry Pi Integration","text":"<p>For the actual integration in Grafana Cloud, please follow the official documentation.</p> <p>tldr:</p> <ol> <li>In your Grafana Cloud stack, click <code>Connections</code> in the left-hand menu.</li> <li>Find <code>Raspberry Pi</code> and click its tile to open the integration.</li> <li>Review the prerequisites in the <code>Configuration Details</code> tab and set up Grafana Agent to send Raspberry Pi metrics and logs to your Grafana Cloud instance. (Note: Check next section on the detailed setup.)</li> <li>Click <code>Install</code> to add this integration\u2019s pre-built dashboards and alerts to your Grafana Cloud instance, and you can start monitoring your Raspberry Pi setup.</li> </ol>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#setup-alloy-in-docker","title":"Setup Alloy in Docker","text":"<p>I've installed Docker on my Raspberry Pi, which runs the Alloy agent along with a few other services. I created a Dockerfile that copies all the necessary configurations for Alloy and pushes the image to my private GitHub Registry.</p> <p>(Goodbye, Docker Hub! I'm tired of dealing with rate limits on the free tier...)</p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#configuring-alloy","title":"Configuring Alloy","text":"<p>Pull the required alloy config from the Raspberry PI integration in Grafana Cloud. For example, here is my config: </p>config.alloy<pre><code>remotecfg {\n    url            = \"https://&lt;YOUR_GRAFANA_REMOTE_FLEET_ENDPOINT&gt;\"\n    id             = \"kavinrpi\"\n    poll_frequency = \"60s\"\n\n    basic_auth {\n        username = \"\"*******\"\n        password = \"*******\"\n    }\n}\n\nprometheus.exporter.unix \"integrations_node_exporter\" { }\n\ndiscovery.relabel \"integrations_node_exporter\" {\n    targets = prometheus.exporter.unix.integrations_node_exporter.targets\n\n    rule {\n        target_label = \"instance\"\n        replacement  = \"kavinrpi\"\n    }\n\n    rule {\n        target_label = \"job\"\n        replacement  = \"integrations/raspberrypi-node\"\n    }\n}\n\nprometheus.scrape \"integrations_node_exporter\" {\n    targets    = discovery.relabel.integrations_node_exporter.output\n    forward_to = [prometheus.relabel.integrations_node_exporter.receiver]\n    job_name   = \"integrations/node_exporter\"\n}\n\n// Very minimal metrics which I export, you could add others as well\nprometheus.relabel \"integrations_node_exporter\" {\n    forward_to = [prometheus.remote_write.metrics_service.receiver]\n\n    rule {\n        source_labels = [\"__name__\"]\n        regex         = \"up|node_boot_time_seconds|node_cpu_seconds_total|node_disk_io_time_seconds_total|node_disk_io_time_weighted_seconds_total|node_disk_read_bytes_total|node_disk_written_bytes_total|node_filesystem_avail_bytes|node_filesystem_files|node_filesystem_files_free|node_filesystem_readonly|node_filesystem_size_bytes|node_hwmon_temp_celsius|node_load1|node_load15|node_load5|node_memory_Buffers_bytes|node_memory_Cached_bytes|node_memory_MemAvailable_bytes|node_memory_MemFree_bytes|node_memory_MemTotal_bytes|node_memory_Slab_bytes|node_memory_SwapTotal_bytes|node_network_receive_bytes_total|node_network_receive_drop_total|node_network_receive_errs_total|node_network_receive_packets_total|node_network_transmit_bytes_total|node_network_transmit_drop_total|node_network_transmit_errs_total|node_network_transmit_packets_total|node_os_info|node_systemd_unit_state|node_uname_info|node_vmstat_pgmajfault\"\n        action        = \"keep\"\n    }\n}\n\n// Write metrics to your Grafana Cloud Prometheus instance\nprometheus.remote_write \"metrics_service\" {\n    endpoint {\n        url = \"https://&lt;YOUR_PROMETHEUS_ENDPOINT&gt;/api/prom/push\"\n\n        basic_auth {\n            username = \"*******\"\n            password = \"*******\"\n        }\n    }\n}\n</code></pre><p></p> <p>All the above endpoints will be available once you complete the steps in the Raspberry Pi integration window in Grafana Cloud.</p> <p>To enable log collection, append the following configuration to your <code>config.alloy</code> </p><pre><code>discovery.relabel \"logs_integrations_integrations_node_exporter_journal_scrape\" {\n    targets = []\n\n    rule {\n        source_labels = [\"__journal__systemd_unit\"]\n        target_label  = \"unit\"\n    }\n\n    rule {\n        source_labels = [\"__journal__boot_id\"]\n        target_label  = \"boot_id\"\n    }\n\n    rule {\n        source_labels = [\"__journal__transport\"]\n        target_label  = \"transport\"\n    }\n\n    rule {\n        source_labels = [\"__journal_priority_keyword\"]\n        target_label  = \"level\"\n    }\n}\n\nloki.source.journal \"logs_integrations_integrations_node_exporter_journal_scrape\" {\n    max_age       = \"24h0m0s\"\n    relabel_rules = discovery.relabel.logs_integrations_integrations_node_exporter_journal_scrape.rules\n    forward_to    = [loki.write.grafana_cloud_loki.receiver]\n    labels        = {\n        instance = constants.hostname,\n        job      = \"integrations/raspberrypi-node\",\n    }\n}\n\nlocal.file_match \"logs_integrations_integrations_node_exporter_direct_scrape\" {\n    path_targets = [{\n        __address__ = \"localhost\",\n        __path__    = \"/var/log/{syslog,messages,*.log}\",\n        instance    = constants.hostname,\n        job         = \"integrations/raspberrypi-node\",\n    }]\n}\n\nloki.source.file \"logs_integrations_integrations_node_exporter_direct_scrape\" {\n    targets    = local.file_match.logs_integrations_integrations_node_exporter_direct_scrape.targets\n    forward_to = [loki.write.grafana_cloud_loki.receiver]\n}\n</code></pre><p></p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#creating-dockerfile","title":"Creating Dockerfile","text":"Dockerfile<pre><code>FROM grafana/alloy:v1.3.1\n\n# Copy the custom config file into the image\nCOPY ./configs/rpi-config.alloy /etc/alloy/config.alloy\n\nCMD [\"run\", \"--server.http.listen-addr=0.0.0.0:12345\", \"--stability.level=public-preview\", \"/etc/alloy/config.alloy\"]\n</code></pre> <p>Now, you can build and push the images to your registry. For example, I use Podman as my container management tool </p>Build &amp; Push Images<pre><code>## Build &amp; Push using podman with multi-arch images\npodman manifest create rpi-alloy\npodman build -f rpi.Dockerfile --platform linux/amd64,linux/arm64 -t &lt;REGISTRY&gt;/&lt;USERNAME&gt;/alloy:rpi-0.1.0 --manifest localhost/rpi-alloy\npodman manifest push localhost/rpi-alloy &lt;REGISTRY&gt;/&lt;USERNAME&gt;/alloy:rpi-0.1.0\n</code></pre><p></p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#fleet-management","title":"Fleet Management","text":"<p>Once the agent is up and running on your Raspberry Pi, it will appear in the fleet management dashboard, as shown below. You can add multiple agents depending on your setup and monitoring needs.</p> <p></p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#dashboards-alerting","title":"Dashboards &amp; Alerting","text":"<p>By default, when you set up the integration, Grafana automatically installs dashboards for both logs and metrics. Alert recording rules comes by default as well for these dashboards, you can cusomtize the alerting as you wish. Here\u2019s how they look:</p> <p>Dashboard:</p> <p></p> <p>Alert Rules:</p> <p></p> <p>Under Alerts &amp; IRM -&gt; Alerting -&gt; Contact Points add your default email contact for notifications.</p> <p></p>"},{"location":"blog/2025/02/22/monitoring-rpi-using-grafana-cloud--alloy/#final-points","title":"Final points","text":"<p>Monitoring my Raspberry Pi with Grafana Alloy and Grafana Cloud proved to be an easy and effective solution. Alloy collects system metrics and logs, while Grafana Cloud provides a reliable, hassle-free observability platform. With this setup, I have real-time insights into my Pi. In the future, I may explore Loki for enhanced logging and setup monitoring PiHole as well. How do you monitor your homelab? \ud83d\ude80</p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/","title":"Self-Hosting Pangolin: My Simple Setup for Accessing Homelab","text":""},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#self-hosting-pangolin-my-simple-setup-for-accessing-homelab","title":"Self-Hosting Pangolin: My Simple Setup for Accessing Homelab","text":""},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#problem","title":"Problem","text":"<p>Anyone who self-hosts eventually hits the same problem - how do you expose services to the internet securely without complicating your entire setup? Sure, you can buy a static IP and forward ports, but that comes with cost, security risks, and the chance of exposing your whole network. I wanted none of that. I didn\u2019t want to:</p> <ul> <li>Open random ports on my router</li> <li>Maintain reverse proxy configs</li> <li>Expose my entire Kubernetes cluster</li> <li>Deal with VPN or DNS hassles</li> </ul> <p>So I started looking for a simpler, safer way.</p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#what-is-pangolin","title":"What is Pangolin?","text":"<p>Pangolin is a lightweight, self-hosted reverse proxy tunnel that lets you securely expose services running in your private network\u2014without opening ports or relying on third-party tunnels.</p> <p>Think of it as your own self-hosted alternative to tools like Cloudflare Tunnel or FRP, but much simpler to deploy and easier to manage. Pangolin runs two components:</p> <ul> <li>Pangolin Server (public-facing): Runs on your VPS or any machine with a public IP.<ul> <li>Pangolin itself - Dashboard, Authentication etc.,</li> <li>Gerbil - Wireguard interface</li> <li>Traefik - Reverse proxy</li> </ul> </li> <li>Pangolin Agent (private): Runs in your homelab and connects out to the server.</li> </ul> <p>Once connected, Pangolin securely routes incoming traffic from the VPS to your internal services, without exposing your LAN or Kubernetes cluster directly.</p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#my-homelab-architecture-high-level","title":"My Homelab Architecture (High-Level)","text":"<p>Below is a high-level overview of how my Pangolin setup integrates with my homelab Kubernetes network and how the services are exposed externally. I\u2019ll save the deep-dive architecture and technical internals for a separate blog, but this overview should give you a clear picture of the setup for now.</p> <p></p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#setting-up-pangolin","title":"Setting Up Pangolin","text":""},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#prerequesites","title":"Prerequesites","text":"<p>From the docs:</p> <ol> <li>Linux server with root access and public IP address.</li> <li>Domain name pointing to your server\u2019s IP address for the dashboard.</li> <li>Email address for Let\u2019s Encrypt SSL certificates and admin login for the dashboard.</li> <li>Open ports on firewall for 80 (TCP), 443 (TCP), 51820 (UDP), and 21820 (UDP for clients)</li> </ol>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#pangolin-server-runs-on-my-vps","title":"Pangolin Server \u2013 runs on my VPS","text":"<p>This is the only public-facing part of the setup. I don't want to explain every detail of deploying the server itself, I deployed it on my VPS using Docker Compose as mentioned in docs here, and it listens for incoming traffic from the internet. All site, resources routing rules and service mappings are configured in Pangolin Dashboard once deployed.</p> <p>Respective <code>config.yml</code> for the server. </p><pre><code>## config.yml\napp:\n  dashboard_url: \"https://pangolin.example.com\"\n\ndomains:\n  domain1:\n    base_domain: \"pangolin.example.com\"\n    cert_resolver: \"letsencrypt\"\n\nserver:\n  # Note: This should be saved for the newt agent for comm's\n  secret: \"your-strong-secret\"\n\ngerbil:\n  base_endpoint: \"pangolin.example.com\"\n\nflags:\n  require_email_verification: true\n  disable_signup_without_invite: true\n  disable_user_create_org: true\n</code></pre><p></p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#newt-agent-k8s-deployment","title":"Newt Agent \u2013 K8s deployment","text":"<p>Pangolin Tunnel can be installed in 3 ways:</p> <ol> <li>Newt Tunnel - Recommended way for tunnel creation.</li> <li>Basic Wireguard - Complicated way, needs WireGuard client and NAT setup.</li> <li>Local - no tunneling, just want to run locally using Pangolin features.</li> </ol> <p>In this setup, I had proceeded with Newt tunnel mode for agent communication.</p> <ul> <li>Since my entire setup follows a GitOps workflow, I use Sealed Secrets to securely manage and deploy the Pangolin credentials. Note: The <code>NEWT_ID</code> and <code>NEWT_SECRET</code> can fetched once you create your site from the Pangolin Dashboard. <pre><code>## Create .env file with secrets\nNEWT_ID=**************\nPANGOLIN_ENDPOINT=https://pangolin.example.com\nNEWT_SECRET=**************\n\n## Create Envs for newt\nkubectl create secret generic newt-cred -n pangolin --from-env-file=newt-cred.env --dry-run=client -o yaml &gt; newt-secret.yaml\n\n## Seal using kubeseal\nkubeseal --format yaml --controller-namespace kubeseal --controller-name kubeseal-sealed-secrets &lt; newt-secret.yaml &gt; ./credentials.yaml\n\n## credentials.yaml\napiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\nname: newt-cred\nnamespace: pangolin\nspec:\nencryptedData:\n    NEWT_ID: *************************\n    NEWT_SECRET: *************************\n    PANGOLIN_ENDPOINT: *************************\ntemplate:\n    metadata:\n    name: newt-cred\n    namespace: pangolin\n</code></pre></li> <li>Newt instances are deployed using the official helm chart <pre><code>## Newt install\nhelm repo add fossorial https://charts.fossorial.io\nhelm repo update fossorial\n\nhelm install pangolin-newt fossorial/newt -f values.yaml\n\n## values.yaml\nnewtInstances:\n  - name: my-homelab\n    enabled: true\n    service:\n      annotations:\n        metallb.io/loadBalancerIPs: 192.168.0.111\n    auth:\n      existingSecretName: newt-cred\n      keys:\n        endpointKey: PANGOLIN_ENDPOINT\n        idKey: NEWT_ID\n        secretKey: NEWT_SECRET\n</code></pre></li> </ul>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#exposing-services","title":"Exposing services","text":"<p>Once both the Pangolin Server and Agent were running, exposing my Kubernetes services became straightforward. Instead of creating Ingress rules, configuring LoadBalancers, or dealing with port mappings, all I had to do was define how each service should be routed through Pangolin.</p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#creating-sites","title":"Creating Sites","text":"<p>This would be the first step when you onboard the newt agent in your home network.</p> <ol> <li>Create a new Site in the Pangolin dashboard and give it any meaningful name.</li> <li>Assign an address to the Site from your organization\u2019s subnet - in most cases, the default value works perfectly fine.</li> <li>A Site contains resources, and these resources automatically form encrypted WireGuard tunnels, all without opening ports or exposing any internal services.</li> </ol> <p></p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#mapping-resources","title":"Mapping Resources","text":"<p>Resources allow you to define the destination endpoints for your services and even distribute traffic across multiple backends for load balancing.</p> <ul> <li>You can configure all the Layer-7 features you\u2019d expect, including path-based routing, rewrite rules, and more.</li> <li>Make sure to map a verified domain from your domain list.</li> <li>One thing to keep in mind about domains: if you want to use a subdomain under the base endpoint you specified during installation, you may need to create an additional <code>A</code> record in your DNS provider that points to your VPS. This is only necessary if your root domain isn\u2019t already mapped to the VPS.</li> <li>For example: my root domain is used for hosting a public site, but <code>auth.example.com</code> (which points to my VPS via an <code>A</code> record) is dedicated for the Pangolin dashboard. Now I'll be creating individual subdomains in Pangolin and mark them as verified by creating an <code>A</code> record to the VPS.</li> <li>In the target configuration, we route the traffic to the internal <code>svc.cluster.local</code> DNS or the metal LB IP that you provisioned for the services.</li> <li>Enable Pangolin SSO Authentication if needed and now you're good to go!</li> </ul> <p></p>"},{"location":"blog/2025/12/06/self-hosting-pangolin-my-simple-setup-for-accessing-homelab/#wrapping-up","title":"Wrapping up","text":"<p>Setting up Pangolin for my homelab turned out to be one of the simplest and cleanest ways to securely expose my services to the internet without touching router configs, opening ports, or relying on third-party SaaS tunnels (even Pangolin has a cloud version). With a lightweight server on my VPS and an agent running inside my cluster, everything stays private while still being accessible from anywhere.</p> <p>If you're tinkering with homelabs or looking for a self-hosted tunnel alternative, Pangolin is definitely worth exploring!</p>"},{"location":"projects/crossplane-docs/","title":"Crossplane Docs","text":""},{"location":"projects/crossplane-docs/#what-is-xdocs","title":"What is XDocs?","text":"<ul> <li>We have XR, XRD, XRC ;) Why not XDocs?</li> <li>Inspired from terraform-docs but for Crossplane</li> <li>Generate markdown based docs for your Compositions, it also includes your linked Resources, XRD and Claim</li> </ul>"},{"location":"projects/crossplane-docs/#installation","title":"Installation","text":"<p>XDocs Generator can be installed in several ways to suit your preferences and development environments</p>"},{"location":"projects/crossplane-docs/#homebrew-tap-macos-linux","title":"Homebrew Tap (macOS &amp; Linux)","text":"<p>If you're using Homebrew, you can install the tool via our custom Homebrew tap</p> <pre><code>brew tap Kavinraja-G/tap\nbrew install crossplane-docs\n</code></pre>"},{"location":"projects/crossplane-docs/#standalone-binary","title":"Standalone Binary","text":"<p>For macOS, Linux, and Windows, standalone binaries are available. Download the appropriate binary for your operating system from the releases page, then move it to a directory in your PATH.</p>"},{"location":"projects/crossplane-docs/#macoslinux","title":"macOS/Linux","text":"<pre><code># Feel free to change the release/arch names accordingly\ncurl -Lo crossplane-docs https://github.com/Kavinraja-G/crossplane-docs/releases/download/v0.1.2/crossplane-docs_v0.1.2_darwin_amd64.tar.gz\nchmod +x crossplane-docs\nsudo mv crossplane-docs /usr/local/bin/\n</code></pre>"},{"location":"projects/crossplane-docs/#windows","title":"Windows","text":"<p>Download the <code>.exe</code> file and add it to your <code>PATH</code></p>"},{"location":"projects/crossplane-docs/#usage","title":"Usage","text":"<p>Currently xDocs supports only markdown output, but more in pipeline. To generate markdown docs for your compositions &amp; XRDs </p><pre><code>crossplane-docs md [INPUT_PATH|INPUT_FILE] -o [OUTPUT_FILE]\n</code></pre> For example: <pre><code>crossplane-docs md ./samples -o samples/README.md\n</code></pre> Check README.md for the output.<p></p>"},{"location":"projects/crossplane-docs/#features","title":"Features","text":"<ul> <li>Discovers Composition &amp; its resources, XR, XRD and Claim names with their references</li> <li>Markdown ouput with tabulation</li> <li>Claim/XRC specifications (WIP)</li> </ul>"},{"location":"projects/crossplane-docs/#limitations","title":"Limitations","text":"<p>Crossplane compositions with Pipeline composition mode is not supported.</p>"},{"location":"projects/local-pv-cleaner/","title":"Local PV Cleaner","text":""},{"location":"projects/local-pv-cleaner/#local-pv-cleaner","title":"local-pv-cleaner","text":"<p>Simple K8s controller to clean-up orphaned local PVs (using nvme's).</p>"},{"location":"projects/local-pv-cleaner/#problem","title":"Problem","text":"<p>We often use projects like TopoLVM and OpenEBS LocalPV to provision PersistentVolumes (PVs) backed by ephemeral local-instance storage, such as NVMe disks on AWS EC2 instances. Even when the retention policy is set to <code>Retain</code>, the underlying storage is lost when the instance shuts down. This results in orphaned PVs, leading to errors when Kubernetes attempts to reattach them especially if a new node reuses the same IP address. Most of the CSI drivers won't delete the PVs in these scenarios.</p> <p>To address this, we need a solution that continuously monitors these scenarios and automatically deletes orphaned PVs.</p>"},{"location":"projects/local-pv-cleaner/#features","title":"Features","text":"<ul> <li>Automatic orphaned PV cleanup: Identifies and deletes PVs that are not bound to any existing node.</li> <li>Dry-run mode: Allows testing without performing actual deletions.</li> <li>Configurable Volume Node Affinity labels: Supports custom node selector labels for determining volume node affinity. Since, CSI drivers define their own topology label.</li> <li>StorageClass Filters: Allows filter the volumes based on multiple storage classes.</li> </ul>"},{"location":"projects/local-pv-cleaner/#installation","title":"Installation","text":"<p>To deploy the Local PV Cleanup Controller in your Kubernetes cluster using Kustomize plugin in Kubectl: </p><pre><code>kubectl apply -k https://github.com/Kavinraja-G/local-pv-cleaner/blob/main/config/default/kustomization.yaml\n</code></pre><p></p>"},{"location":"projects/local-pv-cleaner/#configuration","title":"Configuration","text":"<p>The controller supports the following additional flags than the default flags:</p> Flag Default Description <code>--dry-run</code> <code>false</code> Run in dry-run mode without making actual changes. <code>--node-selector-keys</code> <code>topology.topolvm.io/node</code> Comma-separated list of labels used in PV node affinity to determine the node name. <code>--storage-class-names</code> <code>topolvm</code> Comma-separated list of StorageClass Names used to filter the PVs. <code>--requeue-duration</code> <code>15m</code> Duration for PV reconciler requeue if the node exists (e.g., 5m, 10m, 1h)."},{"location":"projects/nodegizmo/","title":"Nodegizmo","text":"<p>A small command-line utility for your Kubernetes nodes.</p>"},{"location":"projects/nodegizmo/#installation","title":"Installation","text":"<p><code>nodegizmo</code> kubectl plugin is available in krew plugin manager. Anyone can install with the following steps:</p> <ul> <li>Install <code>krew</code> for kuebctl using the following doc.</li> <li>Run <code>kubectl krew install nodegizmo</code></li> </ul>"},{"location":"projects/nodegizmo/#features","title":"Features","text":""},{"location":"projects/nodegizmo/#nodegizmo-node","title":"nodegizmo node","text":"<p>This command displays the generic node related information. For example:</p> <ul> <li>NodeName</li> <li>K8sVersion</li> <li>Image</li> <li>OS &amp; Architecture info</li> <li>NodeStatus (Ready/NotReady)</li> <li>Taints</li> <li>Node Provider (AWS/Azure/GCP)</li> <li>Topology info (Region &amp; Zone)</li> </ul> <p></p>"},{"location":"projects/nodegizmo/#nodegizmo-node-capacity","title":"nodegizmo node capacity","text":"<p>Node Capacity information</p> <ul> <li>CPU</li> <li>Memory</li> <li>Disk</li> <li>Ephemeral storage</li> <li>Pod capacities</li> <li>Nodepool related information</li> </ul> <p></p>"},{"location":"projects/nodegizmo/#nodegizmo-nodepool","title":"nodegizmo nodepool","text":"<p>Nodepool related information</p> <ul> <li>Grouped by NodePool ID</li> <li>Node list</li> <li>Topology info (Region &amp; Zone)</li> <li>Instance type</li> <li>K8sVersion</li> <li>Nodepool provider (supported: EKS/AKS/GKE/Karpenter)</li> </ul> <p></p>"},{"location":"projects/nodegizmo/#nodegizmo-exec-nodename","title":"nodegizmo exec nodeName","text":"<p>Exec into any node by spawning a <code>nsenter</code> pod automatically based on the node selection.</p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2025/#2025","title":"2025","text":""},{"location":"blog/category/homelab/","title":"HomeLab","text":""},{"location":"blog/category/homelab/#homelab","title":"HomeLab","text":""},{"location":"blog/category/monitoring/","title":"Monitoring","text":""},{"location":"blog/category/monitoring/#monitoring","title":"Monitoring","text":""}]}